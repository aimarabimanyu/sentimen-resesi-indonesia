{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:25.087691400Z",
     "start_time": "2023-07-26T10:56:11.932180900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('resesi-class.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:25.359964Z",
     "start_time": "2023-07-26T10:56:25.145536800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0                                          full_text sentiment\n3385        3385  Survei Sebut Potensi Indonesia Resesi Ekonomi ...  positive\n3386        3386  Indonesia hanya berptensi sebesar tiga persen ...  positive\n3387        3387  Moga resesi tak terjadi di Indonesia. #Wujudka...  positive\n3388        3388  Indonesia hanya berpotensi sebesar 3% untuk re...  positive\n3389        3389  Indonesia hanya memiliki potensi sebesar tiga ...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>full_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3385</th>\n      <td>3385</td>\n      <td>Survei Sebut Potensi Indonesia Resesi Ekonomi ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3386</th>\n      <td>3386</td>\n      <td>Indonesia hanya berptensi sebesar tiga persen ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3387</th>\n      <td>3387</td>\n      <td>Moga resesi tak terjadi di Indonesia. #Wujudka...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3388</th>\n      <td>3388</td>\n      <td>Indonesia hanya berpotensi sebesar 3% untuk re...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3389</th>\n      <td>3389</td>\n      <td>Indonesia hanya memiliki potensi sebesar tiga ...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:25.525524Z",
     "start_time": "2023-07-26T10:56:25.324059700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimar\\AppData\\Local\\Temp\\ipykernel_2908\\3284801822.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataset['full_text'] = dataset['full_text'].str.replace(r'[?]+', ' ').str.replace(r'RT @', ' ').str.replace(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ').str.replace(r'@[^\\s]+', '').str.replace(r'\\\\n', ' ').str.replace(r'[\\s]+', ' ').str.replace('\\s+', ' ', regex=True).str.replace(r'#([^\\s]+)', r'')\n"
     ]
    }
   ],
   "source": [
    "# Cleaning The Datasets\n",
    "dataset['full_text'] = dataset['full_text'].str.encode('ascii', 'replace').str.decode('ascii')\n",
    "dataset['full_text'] = dataset['full_text'].str.replace(r'[?]+', ' ').str.replace(r'RT @', ' ').str.replace(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ').str.replace(r'@[^\\s]+', '').str.replace(r'\\\\n', ' ').str.replace(r'[\\s]+', ' ').str.replace('\\s+', ' ', regex=True).str.replace(r'#([^\\s]+)', r'')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:29.631441700Z",
     "start_time": "2023-07-26T10:56:25.406838300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      Unnamed: 0                                          full_text sentiment\n3385        3385  Survei Sebut Potensi Indonesia Resesi Ekonomi ...  positive\n3386        3386  Indonesia hanya berptensi sebesar tiga persen ...  positive\n3387        3387            Moga resesi tak terjadi di Indonesia.    positive\n3388        3388  Indonesia hanya berpotensi sebesar 3% untuk re...  positive\n3389        3389  Indonesia hanya memiliki potensi sebesar tiga ...  positive",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>full_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3385</th>\n      <td>3385</td>\n      <td>Survei Sebut Potensi Indonesia Resesi Ekonomi ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3386</th>\n      <td>3386</td>\n      <td>Indonesia hanya berptensi sebesar tiga persen ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3387</th>\n      <td>3387</td>\n      <td>Moga resesi tak terjadi di Indonesia.</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3388</th>\n      <td>3388</td>\n      <td>Indonesia hanya berpotensi sebesar 3% untuk re...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3389</th>\n      <td>3389</td>\n      <td>Indonesia hanya memiliki potensi sebesar tiga ...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:29.670338700Z",
     "start_time": "2023-07-26T10:56:29.579581200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataset.to_csv('resesi-class-clean.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:29.735165100Z",
     "start_time": "2023-07-26T10:56:29.607506400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split Datasets, Tokenize, Padding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#Parameters\n",
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 50\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .9"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:29.831906200Z",
     "start_time": "2023-07-26T10:56:29.690284700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Split Datasets\n",
    "x_train, x_test = train_test_split(dataset['full_text'], train_size = training_portion, shuffle = False)\n",
    "y_train, y_test = train_test_split(dataset['sentiment'], train_size = training_portion, shuffle = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:29.921969200Z",
     "start_time": "2023-07-26T10:56:29.723196300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3051,)\n",
      "(339,)\n",
      "(3051,)\n",
      "(339,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T11:05:59.673016Z",
     "start_time": "2023-07-26T11:05:59.632612400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#Tokenize and Pad Sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "train_padding = pad_sequences(train_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "test_padding = pad_sequences(test_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:30.113944400Z",
     "start_time": "2023-07-26T10:56:29.772068200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#Tokenize and Pad Labels\n",
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(dataset['sentiment'])\n",
    "\n",
    "train_label_seq = label_tokenizer.texts_to_sequences(y_train)\n",
    "test_label_seq = label_tokenizer.texts_to_sequences(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:30.221656400Z",
     "start_time": "2023-07-26T10:56:30.118931500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_label_seq = np.array(train_label_seq)\n",
    "test_label_seq = np.array(test_label_seq)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:30.237613800Z",
     "start_time": "2023-07-26T10:56:30.224648700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3051,)\n",
      "(339,)\n",
      "(3051, 1)\n",
      "(339, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(train_label_seq.shape)\n",
    "print(test_label_seq.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T11:09:18.815552300Z",
     "start_time": "2023-07-26T11:09:18.778621500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#Model Architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:56:36.199249Z",
     "start_time": "2023-07-26T10:56:30.242601600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 10s 15ms/step - loss: nan - accuracy: 0.0016 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 1s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 2s 19ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 1s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 1s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 1s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 1s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 1s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 1s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 2s 16ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 1s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 1s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 2s 17ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 1s 16ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 1s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 1s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 2s 18ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 1s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 1s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 1s 15ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 1s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x21399bb16d0>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Train\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_padding,\n",
    "    train_label_seq,\n",
    "    epochs = 50,\n",
    "    validation_data = (test_padding, test_label_seq),\n",
    "    verbose = 1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:57:47.386365500Z",
     "start_time": "2023-07-26T10:56:36.200247100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16)\n"
     ]
    }
   ],
   "source": [
    "# Get the index-word dictionary\n",
    "reverse_word_index = tokenizer.index_word\n",
    "\n",
    "# Get the embedding layer from the model (i.e. first layer)\n",
    "embedding_layer = model.layers[0]\n",
    "\n",
    "# Get the weights of the embedding layer\n",
    "embedding_weights = embedding_layer.get_weights()[0]\n",
    "\n",
    "# Print the shape. Expected is (vocab_size, embedding_dim)\n",
    "print(embedding_weights.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:57:47.494080900Z",
     "start_time": "2023-07-26T10:57:47.401327200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Open writeable files\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Initialize the loop. Start counting at `1` because `0` is just for the padding\n",
    "for word_num in range(1, vocab_size):\n",
    "\n",
    "  # Get the word associated at the current index\n",
    "  word_name = reverse_word_index[word_num]\n",
    "\n",
    "  # Get the embedding weights associated with the current index\n",
    "  word_embedding = embedding_weights[word_num]\n",
    "\n",
    "  # Write the word name\n",
    "  out_m.write(word_name + \"\\n\")\n",
    "\n",
    "  # Write the word embedding\n",
    "  out_v.write('\\t'.join([str(x) for x in word_embedding]) + \"\\n\")\n",
    "\n",
    "# Close the files\n",
    "out_v.close()\n",
    "out_m.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:57:47.497078100Z",
     "start_time": "2023-07-26T10:57:47.420275200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T10:57:47.497078100Z",
     "start_time": "2023-07-26T10:57:47.469144700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
